{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Benchmark\n",
    "\n",
    "Since we are going to play a bit with data and datasets - ultimately to show some examples of data analysis and machine learning - \n",
    "**in this notebook** we will present a quite new package in the Python ecosystem, i.e. `pmlb` that automatically provides datasets for data analysis and Machine Learning.\n",
    "\n",
    "\n",
    "### Don't worry\n",
    "\n",
    "If you are an absolute beginner, or you simply don't know what Machine Learning is, **nothing to worry about**!\n",
    "We will talk about it in the next section! :)\n",
    "\n",
    "**In this notebook** we just focus on the `pmlb` package from a technical perspective. \n",
    "\n",
    "If you are completely new to concepts like **Supervised Learning**, **Classification**, or **Regression** come back to this notebook later after the \"Introduction to Machine Learning\" section for a quick recap and cross-check of these concepts !-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducting the Penn Machine Learning Benchmarks\n",
    "\n",
    "**Penn Machine Learning Benchmark** (`PMLB`) is a collection of code and data for a large, curated set of benchmark datasets for evaluating and comparing supervised machine learning algorithms. \n",
    "\n",
    "These data sets cover a broad range of applications, and include _binary/multi-class classification_ problems and _regression problems_, as well as combinations of categorical, ordinal, and continuous features. \n",
    "\n",
    "**There are no missing values in these data sets**.\n",
    "\n",
    "PMLB was developed in the [Computational Genetics Lab](http://epistasis.org/) at the [University of Pennsylvania](https://www.upenn.edu/) with funding from the [NIH](http://www.nih.gov/) under grant R01 AI117694. \n",
    "\n",
    "More information here: [github.com/EpistasisLab/penn-ml-benchmarks](https://github.com/EpistasisLab/penn-ml-benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set format\n",
    "\n",
    "All data sets are stored in a common format:\n",
    "\n",
    "* First row is the column names\n",
    "* Each following row corresponds to one row of the data\n",
    "* The target column is named `target`\n",
    "* All columns are tab (`\\t`) separated\n",
    "* All files are compressed with `gzip` to conserve space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python wrapper\n",
    "\n",
    "For easy access to the benchmark data sets, we have provided a Python wrapper named `pmlb`. The wrapper can be installed on Python via `pip`:\n",
    "\n",
    "```\n",
    "pip install pmlb\n",
    "```\n",
    "\n",
    "and used in Python scripts as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    import plmb\n",
    "except ImportError:\n",
    "    print('IMPORT ERROR: Please install the pmlb package: pip install pmlb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you got an ImportError in the previous cell:\n",
    "\n",
    "!pip install pmlb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset List\n",
    "\n",
    "You can list **all** the available data sets in `pmlb` as it follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pmlb import dataset_names\n",
    "\n",
    "print('All Available Datasets: ')\n",
    "print('========================')\n",
    "for i, name in enumerate(dataset_names):\n",
    "    print('{}) {}'.format(i+1, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, if you are particularly interested in getting the list of available datasets for **Classification** or **Regression**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pmlb import classification_dataset_names, regression_dataset_names\n",
    "\n",
    "print('Classification Datasets: ')\n",
    "print('=========================')\n",
    "for i, name in enumerate(classification_dataset_names):\n",
    "    print('{}) {}'.format(i+1, name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regression Datasets: ')\n",
    "print('=========================')\n",
    "for i, name in enumerate(regression_dataset_names):\n",
    "    print('{}) {}'.format(i+1, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching a Dataset\n",
    "\n",
    "To fetch data from a dataset in `pmlb` it is just necessary the **name** of the dataset. \n",
    "\n",
    "By default, a `pandas.DataFrame` will be returned as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a pandas DataFrame\n",
    "from pmlb import fetch_data\n",
    "\n",
    "adult_data = fetch_data('adult')\n",
    "print(adult_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebooks, we will be using this **package** to easily download and use datasets for further analysis and manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel free to SKIP \n",
    "\n",
    "Please feel free to **skip** the rest of this notebook and come back to it later once we will introduce **NumPy**, and \n",
    "**Scikit-learn** for Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_data` function has two additional parameters:\n",
    "\n",
    "* `return_X_y` (True/False): Whether to return the data in scikit-learn format, with the features and labels stored in separate NumPy arrays.\n",
    "\n",
    "* `local_cache_dir` (string): The directory on your local machine to store the data files so you don't have to fetch them over the web again. By default, the wrapper does not use a local cache directory.\n",
    "\n",
    "For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "\n",
    "# Returns NumPy arrays\n",
    "adult_X, adult_y = fetch_data('adult', return_X_y=True, local_cache_dir='./data')\n",
    "print(adult_X)\n",
    "print(adult_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Example usage: Compare two classification algorithms with PMLB\n",
    "\n",
    "PMLB is designed to make it easy to benchmark machine learning algorithms against each other. \n",
    "\n",
    "Below is a Python code snippet showing the most basic way to use PMLB to compare two algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from pmlb import fetch_data, classification_dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_test_scores = []\n",
    "gnb_test_scores = []\n",
    "\n",
    "for i, classification_dataset in enumerate(classification_dataset_names):\n",
    "    if i > 20:\n",
    "        break\n",
    "        \n",
    "    X, y = fetch_data(classification_dataset, return_X_y=True)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "\n",
    "    logit = LogisticRegression(solver='liblinear', multi_class='auto', )\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    logit.fit(train_X, train_y)\n",
    "    gnb.fit(train_X, train_y)\n",
    "\n",
    "    logit_test_scores.append(logit.score(test_X, test_y))\n",
    "    gnb_test_scores.append(gnb.score(test_X, test_y))\n",
    "    print('{} {} DONE'.format(i+1, classification_dataset))\n",
    "\n",
    "sb.boxplot(data=[logit_test_scores, gnb_test_scores], notch=True)\n",
    "plt.xticks([0, 1], ['LogisticRegression', 'GaussianNB'])\n",
    "plt.ylabel('Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
